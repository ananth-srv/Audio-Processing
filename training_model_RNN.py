import tflearn
import numpy as np

data = np.loadtxt("D:/Docs/Audio/Movies/Autograph/save25_data.txt",dtype=int)
label = np.loadtxt("D:/Docs/Audio/Movies/Autograph/save25_label.txt",dtype=int)
word_lexicon = np.genfromtxt("D:/Docs/Audio/Movies/Autograph/save25_lexicon.txt", dtype=str)
data = np.reshape(data, (-1,len(data),np.shape(data)[1]))
print(np.shape(data))
net = tflearn.input_data([None, np.shape(data)[2]])
net = tflearn.embedding(net, input_dim=np.shape(data)[2], output_dim=len(word_lexicon))
print('before lstm')
net = tflearn.lstm(net, 128, dropout=0.8)
print('after lstm')
net = tflearn.fully_connected(net, len(word_lexicon), activation='softmax')
net = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')

# model = tflearn.DNN(net, checkpoint_path='tflearn.dnn.ckpt')
model = tflearn.DNN(net)
# Start training (apply gradient descent algorithm)
print('model fitting in progress...')
model.fit(data, label, n_epoch=2, batch_size=2, show_metric=True)
# model.save("tflearn_dnn.tfl")
print('data shape', np.shape(data))
print('testing model...')
test = np.loadtxt("D:/Docs/Audio/Movies/Autograph/save25_data.txt",dtype=int)
print('test load', np.shape(test))
test = np.reshape(test, (-1,len(test),np.shape(test)[1]))
print('test shape', np.shape(test))
label = np.loadtxt("D:/Docs/Audio/Movies/Autograph/test_label.txt",dtype=int)
pred = model.predict(test)
print(pred)